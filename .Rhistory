estimates_df = lapply(estimates_files, readRDS) %>% rlist::list.rbind(.)
my_nlshrink = function(data){
tryCatch({
S = nlshrink_cov(data, method='nloptr') %>% cov2cor
}, error = function(e){cat("ERROR :",
conditionMessage(e))})
return(S)
}
portfolio_var = function(estimates){
d = estimates$d[1]
delta = estimates$delta[1]
epsilon = estimates$epsilon[1]
consecutive = estimates$consecutive[1]
ndim = 1000
nobs = 1250
phi = c(.1, .8)
# Starting workers
cores = detectCores() # detecting number of cores in the PC
cl = makeCluster(cores-2)
clusterEvalQ(cl, library("robcdcc"))
clusterEvalQ(cl, library("truncnorm"))
clusterEvalQ(cl, library("nlshrink"))
clusterEvalQ(cl, library("cellWise"))
clusterExport(cl, c("my_nlshrink"))
# Simulation
for(i in 1:10){
tryCatch({
cat('\n', 'pt ', i, '\n')
print(Sys.time())
data_path = paste(
'simulation_results/01__high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
sim = readRDS(data_path)
data = map(sim, 1)
seeds = map(sim, 2)
burnin_path = paste(
'simulation_results/00__burnin_high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
burnin_data = readRDS(burnin_path)
bdata = map(burnin_data, 1)
bseeds = map(burnin_data, 2)
all_data = lapply(1:10, function(x){
rbind(bdata[[x]], data[[x]])
})
# Validating
validate_burnin = all_data %>% lapply(anyDuplicated) %>% unlist
if(all(validate_burnin == 102) == FALSE){
print('burnin sample incompatible!')
break
}
# contaminating data
cont_seed = as.list(((i * 10 + 1) : (i * 10  + 10)))
cont_data = mapply(contaminate_high1, data, cont_seed,
MoreArgs = list(d=d, epsilon=epsilon,
consecutive=consecutive),
SIMPLIFY = FALSE)
# Getting estimates
estimates_i = estimates[estimates$seed == i, ]
q_estimates = estimates_i[estimates_i$model == 'Q', ]
r_estimates = estimates_i[estimates_i$model == 'R', ]
seed = q_estimates$seed
q_phi = q_estimates[, c('X1', 'X2')] %>%
split(., seq(nrow(.))) %>% lapply(as.numeric)
r_phi = r_estimates[, c('X1', 'X2')] %>%
split(., seq(nrow(.)))  %>% lapply(as.numeric)
# Portfolio variance
# Robust config
robust_control = c(1.0465, 1.00045, .975)
cy1 = robust_control[1]
cy2 = robust_control[2]
delta = robust_control[3]
# quantile for chi square distribution
chisq1 = qchisq(delta, 1)
chisq2 = qchisq(delta, ndim)
# Calculating all Qs * epsilon
q_Qs = mapply(calc_Qs, q_phi, cont_data, SIMPLIFY = FALSE)
r_Qs = mapply(robust_calc_Qs, r_phi, cont_data,
MoreArgs = list(cy1 = cy1, chisq1 = chisq1),
SIMPLIFY = FALSE)
# Getting real S
S = lapply(seeds, function(x){
set.seed(x * 10)
rho = rtruncnorm(
ndim,
a = .5 - 4 * .1,
b = .5 + 4 * .1,
mean = .5,
sd = .1
)
S = rho %o% rho
diag(S) = rep(1, ndim)
return(S)
})
# Non-Linear Shrinkage covariance estimate
print(Sys.time())
cat('\n', 'shrinkage!', '\n')
wrapper_q_S = parLapply(cl=cl, q_Qs, wrapper_cov) %>% map(2)
wrapper_r_S = parLapply(cl=cl, r_Qs, wrapper_cov) %>% map(2)
q_S = parLapply(cl=cl, wrapper_q_S, nlshrink)
r_S = parLapply(cl=cl, wrapper_r_S, nlshrink)
cat('\n', 'S determinant!', '\n')
q_S_determinant =  q_S %>% lapply(determinant) %>%
map(1) %>% lapply(function(x){return(x[1])}) %>%
unlist
r_S_determinant =  r_S %>% lapply(determinant) %>%
map(1) %>% lapply(function(x){return(x[1])}) %>%
unlist
# Portfolio variance
print(Sys.time())
cat('\n', 'portfolio_var!', '\n')
variance_portfolio = parLapply(
cl = cl,
1:10,
fun=function(x){
tryCatch(
geral_calc_portfolio_variance(phi=phi,
q_phi=estimates[[x]],
r_phi=robust_estimates[[x]],
rt=data[[x]], burn_rt=bdata[[x]],
cont_rt=cont_data[[x]],
S=S[[x]],
q_S=q_S[[x]], r_S=r_S[[x]],
cy2=cy2, chisq2=chisq2)
)}
)
results = lapply(variance_portfolio, t) %>%
rlist::list.rbind(.) %>% as.data.frame
results$q_S_determinant = q_S_determinant
results$r_S_determinant = r_S_determinant
results$d = d
results$consecutive = consecutive
results$epsilon = epsilon
results$seed = i
results$delta = delta
# biding results
results_path = paste(
'simulation_results/03__high_dimension_var_n1250/pt_', i, '_epsilon_',
epsilon, '_d_', d, '_consecutive_', consecutive,'.Rds', sep = "")
# checkpoint
saveRDS(results, file = results_path)
}, error = function(e){cat("ERROR :",
conditionMessage(e), '. iteration:', i, "\n")})
}
stopCluster(cl)
}
estimates_groupby = estimates_df %>%
group_by(d, consecutive, epsilon) %>% group_split
portfolio_var(estimates_groupby[[1]])
'Estimate portfólio variance.'
# Packages
library(dplyr)
library(ggplot2)
library(rlist)
library(Metrics) # RMSE
library(purrr)
library(readr)
library(tidyr) # pivot_wider
library(data.table)
library(lemon) # shared subtitle for grid.arrange
library(miceadds) # source.all
library(Rcpp)
library(RcppArmadillo)
library(parallel)
library(robcdcc)
library(nlshrink)
# Paths
setwd('/home/encrypted/epinheiro/Documentos/Masters-degree')
path = 'simulation_results'
# Functions
source('packages.R')
# Getting estimates
estimates_files = list.files(path = file.path(path, '02__high_dimension_estimates_n1250'),
pattern = "\\.Rds$", full.names = TRUE)
estimates_df = lapply(estimates_files, readRDS) %>% rlist::list.rbind(.)
my_nlshrink = function(data){
tryCatch({
S = nlshrink_cov(data, method='nloptr') %>% cov2cor
}, error = function(e){cat("ERROR :",
conditionMessage(e))})
return(S)
}
portfolio_var = function(estimates){
d = estimates$d[1]
delta = estimates$delta[1]
epsilon = estimates$epsilon[1]
consecutive = estimates$consecutive[1]
ndim = 1000
nobs = 1250
phi = c(.1, .8)
# Starting workers
cores = detectCores() # detecting number of cores in the PC
cl = makeCluster(cores-2)
clusterEvalQ(cl, library("robcdcc"))
clusterEvalQ(cl, library("truncnorm"))
clusterEvalQ(cl, library("nlshrink"))
clusterEvalQ(cl, library("cellWise"))
clusterExport(cl, c("my_nlshrink"))
# Simulation
for(i in 1:10){
tryCatch({
cat('\n', 'pt ', i, '\n')
print(Sys.time())
data_path = paste(
'simulation_results/01__high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
sim = readRDS(data_path)
data = map(sim, 1)
seeds = map(sim, 2)
burnin_path = paste(
'simulation_results/00__burnin_high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
burnin_data = readRDS(burnin_path)
bdata = map(burnin_data, 1)
bseeds = map(burnin_data, 2)
all_data = lapply(1:10, function(x){
rbind(bdata[[x]], data[[x]])
})
# Validating
validate_burnin = all_data %>% lapply(anyDuplicated) %>% unlist
if(all(validate_burnin == 102) == FALSE){
print('burnin sample incompatible!')
break
}
# contaminating data
cont_seed = as.list(((i * 10 + 1) : (i * 10  + 10)))
cont_data = mapply(contaminate_high1, data, cont_seed,
MoreArgs = list(d=d, epsilon=epsilon,
consecutive=consecutive),
SIMPLIFY = FALSE)
# Getting estimates
estimates_i = estimates[estimates$seed == i, ]
q_estimates = estimates_i[estimates_i$model == 'Q', ]
r_estimates = estimates_i[estimates_i$model == 'R', ]
seed = q_estimates$seed
q_phi = q_estimates[, c('X1', 'X2')] %>%
split(., seq(nrow(.))) %>% lapply(as.numeric)
r_phi = r_estimates[, c('X1', 'X2')] %>%
split(., seq(nrow(.)))  %>% lapply(as.numeric)
# Portfolio variance
# Robust config
robust_control = c(1.0465, 1.00045, .975)
cy1 = robust_control[1]
cy2 = robust_control[2]
delta = robust_control[3]
# quantile for chi square distribution
chisq1 = qchisq(delta, 1)
chisq2 = qchisq(delta, ndim)
# Calculating all Qs * epsilon
q_Qs = mapply(calc_Qs, q_phi, cont_data, SIMPLIFY = FALSE)
r_Qs = mapply(robust_calc_Qs, r_phi, cont_data,
MoreArgs = list(cy1 = cy1, chisq1 = chisq1),
SIMPLIFY = FALSE)
# Getting real S
S = lapply(seeds, function(x){
set.seed(x * 10)
rho = rtruncnorm(
ndim,
a = .5 - 4 * .1,
b = .5 + 4 * .1,
mean = .5,
sd = .1
)
S = rho %o% rho
diag(S) = rep(1, ndim)
return(S)
})
# Non-Linear Shrinkage covariance estimate
print(Sys.time())
cat('\n', 'shrinkage!', '\n')
wrapper_q_S = parLapply(cl=cl, q_Qs, wrapper_cov) %>% map(2)
wrapper_r_S = parLapply(cl=cl, r_Qs, wrapper_cov) %>% map(2)
q_S = parLapply(cl=cl, wrapper_q_S, nlshrink_cov)
r_S = parLapply(cl=cl, wrapper_r_S, nlshrink_cov)
cat('\n', 'S determinant!', '\n')
q_S_determinant =  q_S %>% lapply(determinant) %>%
map(1) %>% lapply(function(x){return(x[1])}) %>%
unlist
r_S_determinant =  r_S %>% lapply(determinant) %>%
map(1) %>% lapply(function(x){return(x[1])}) %>%
unlist
# Portfolio variance
print(Sys.time())
cat('\n', 'portfolio_var!', '\n')
variance_portfolio = parLapply(
cl = cl,
1:10,
fun=function(x){
tryCatch(
geral_calc_portfolio_variance(phi=phi,
q_phi=estimates[[x]],
r_phi=robust_estimates[[x]],
rt=data[[x]], burn_rt=bdata[[x]],
cont_rt=cont_data[[x]],
S=S[[x]],
q_S=q_S[[x]], r_S=r_S[[x]],
cy2=cy2, chisq2=chisq2)
)}
)
results = lapply(variance_portfolio, t) %>%
rlist::list.rbind(.) %>% as.data.frame
results$q_S_determinant = q_S_determinant
results$r_S_determinant = r_S_determinant
results$d = d
results$consecutive = consecutive
results$epsilon = epsilon
results$seed = i
results$delta = delta
# biding results
results_path = paste(
'simulation_results/03__high_dimension_var_n1250/pt_', i, '_epsilon_',
epsilon, '_d_', d, '_consecutive_', consecutive,'.Rds', sep = "")
# checkpoint
saveRDS(results, file = results_path)
}, error = function(e){cat("ERROR :",
conditionMessage(e), '. iteration:', i, "\n")})
}
stopCluster(cl)
}
estimates_groupby = estimates_df %>%
group_by(d, consecutive, epsilon) %>% group_split
portfolio_var(estimates_groupby[[1]])
'Estimate portfólio variance.'
# Packages
library(dplyr)
library(ggplot2)
library(rlist)
library(Metrics) # RMSE
library(purrr)
library(readr)
library(tidyr) # pivot_wider
library(data.table)
library(lemon) # shared subtitle for grid.arrange
library(miceadds) # source.all
library(Rcpp)
library(RcppArmadillo)
library(parallel)
library(robcdcc)
library(nlshrink)
# Paths
setwd('/home/encrypted/epinheiro/Documentos/Masters-degree')
path = 'simulation_results'
# Functions
source('packages.R')
# Getting estimates
estimates_files = list.files(path = file.path(path, '02__high_dimension_estimates_n1250'),
pattern = "\\.Rds$", full.names = TRUE)
estimates_df = lapply(estimates_files, readRDS) %>% rlist::list.rbind(.)
my_nlshrink = function(data){
tryCatch({
S = nlshrink_cov(data, method='nloptr') %>% cov2cor
}, error = function(e){cat("ERROR :",
conditionMessage(e))})
return(S)
}
portfolio_var = function(estimates){
d = estimates$d[1]
delta = estimates$delta[1]
epsilon = estimates$epsilon[1]
consecutive = estimates$consecutive[1]
ndim = 1000
nobs = 1250
phi = c(.1, .8)
# Starting workers
cores = detectCores() # detecting number of cores in the PC
cl = makeCluster(cores-2)
clusterEvalQ(cl, library("robcdcc"))
clusterEvalQ(cl, library("truncnorm"))
clusterEvalQ(cl, library("nlshrink"))
clusterEvalQ(cl, library("cellWise"))
clusterExport(cl, c("my_nlshrink"))
# Simulation
for(i in 1:10){
tryCatch({
cat('\n', 'pt ', i, '\n')
print(Sys.time())
data_path = paste(
'simulation_results/01__high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
sim = readRDS(data_path)
data = map(sim, 1)
seeds = map(sim, 2)
burnin_path = paste(
'simulation_results/00__burnin_high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
burnin_data = readRDS(burnin_path)
bdata = map(burnin_data, 1)
bseeds = map(burnin_data, 2)
all_data = lapply(1:10, function(x){
rbind(bdata[[x]], data[[x]])
})
# Validating
validate_burnin = all_data %>% lapply(anyDuplicated) %>% unlist
if(all(validate_burnin == 102) == FALSE){
print('burnin sample incompatible!')
break
}
# contaminating data
cont_seed = as.list(((i * 10 + 1) : (i * 10  + 10)))
cont_data = mapply(contaminate_high1, data, cont_seed,
MoreArgs = list(d=d, epsilon=epsilon,
consecutive=consecutive),
SIMPLIFY = FALSE)
# Getting estimates
estimates_i = estimates[estimates$seed == i, ]
q_estimates = estimates_i[estimates_i$model == 'Q', ]
r_estimates = estimates_i[estimates_i$model == 'R', ]
seed = q_estimates$seed
q_phi = q_estimates[, c('X1', 'X2')] %>%
split(., seq(nrow(.))) %>% lapply(as.numeric)
r_phi = r_estimates[, c('X1', 'X2')] %>%
split(., seq(nrow(.)))  %>% lapply(as.numeric)
# Portfolio variance
# Robust config
robust_control = c(1.0465, 1.00045, .975)
cy1 = robust_control[1]
cy2 = robust_control[2]
delta = robust_control[3]
# quantile for chi square distribution
chisq1 = qchisq(delta, 1)
chisq2 = qchisq(delta, ndim)
# Calculating all Qs * epsilon
q_Qs = mapply(calc_Qs, q_phi, cont_data, SIMPLIFY = FALSE)
r_Qs = mapply(robust_calc_Qs, r_phi, cont_data,
MoreArgs = list(cy1 = cy1, chisq1 = chisq1),
SIMPLIFY = FALSE)
# Getting real S
S = lapply(seeds, function(x){
set.seed(x * 10)
rho = rtruncnorm(
ndim,
a = .5 - 4 * .1,
b = .5 + 4 * .1,
mean = .5,
sd = .1
)
S = rho %o% rho
diag(S) = rep(1, ndim)
return(S)
})
# Non-Linear Shrinkage covariance estimate
print(Sys.time())
cat('\n', 'shrinkage!', '\n')
wrapper_q_S = parLapply(cl=cl, q_Qs, wrapper_cov) %>% map(2)
wrapper_r_S = parLapply(cl=cl, r_Qs, wrapper_cov) %>% map(2)
q_S = parLapply(cl=cl, wrapper_q_S, nlshrink_cov)
r_S = parLapply(cl=cl, wrapper_r_S, nlshrink_cov)
cat('\n', 'S determinant!', '\n')
q_S_determinant =  q_S %>% lapply(determinant) %>%
map(1) %>% lapply(function(x){return(x[1])}) %>%
unlist
r_S_determinant =  r_S %>% lapply(determinant) %>%
map(1) %>% lapply(function(x){return(x[1])}) %>%
unlist
# Portfolio variance
print(Sys.time())
cat('\n', 'portfolio_var!', '\n')
variance_portfolio = parLapply(
cl = cl,
1:10,
fun=function(x){
tryCatch(
geral_calc_portfolio_variance(phi=phi,
q_phi=q_phi[[x]],
r_phi=r_phi[[x]],
rt=data[[x]], burn_rt=bdata[[x]],
cont_rt=cont_data[[x]],
S=S[[x]],
q_S=q_S[[x]], r_S=r_S[[x]],
cy2=cy2, chisq2=chisq2)
)}
)
results = lapply(variance_portfolio, t) %>%
rlist::list.rbind(.) %>% as.data.frame
results$q_S_determinant = q_S_determinant
results$r_S_determinant = r_S_determinant
results$d = d
results$consecutive = consecutive
results$epsilon = epsilon
results$seed = i
results$delta = delta
# biding results
results_path = paste(
'simulation_results/03__high_dimension_var_n1250/pt_', i, '_epsilon_',
epsilon, '_d_', d, '_consecutive_', consecutive,'.Rds', sep = "")
# checkpoint
saveRDS(results, file = results_path)
}, error = function(e){cat("ERROR :",
conditionMessage(e), '. iteration:', i, "\n")})
}
stopCluster(cl)
}
estimates_groupby = estimates_df %>%
group_by(d, consecutive, epsilon) %>% group_split
portfolio_var(estimates_groupby[[1]])
'Estimate portfólio variance.'
# Packages
library(dplyr)
library(ggplot2)
library(rlist)
library(Metrics) # RMSE
library(purrr)
library(readr)
library(tidyr) # pivot_wider
library(data.table)
library(lemon) # shared subtitle for grid.arrange
library(miceadds) # source.all
library(Rcpp)
library(RcppArmadillo)
library(parallel)
library(robcdcc)
library(nlshrink)
wrapper_cov()
