escape_double = FALSE,
locale = locale(grouping_mark = "."),
trim_ws = TRUE
)
estimates_df
wrapper_cov = function(X, estimate_loc_scale = FALSE) {
cutoff <- sqrt(qchisq(0.975, ncol(X)))
if (estimate_loc_scale == TRUE) {
estX = estLocScale(X)
Xw = wrap(X, estX$loc, estX$scale)$Xw
}else{
loc = rep(0, ncol(X))
# scale = rep(1, ncol(X))
estX = estLocScale(X)
Xw = wrap(X, loc, estX$scale)$Xw
}
return(Xw)
}
my_nlshrink = function(data){
S = nlshrink_cov(data, method='nloptr') %>% cov2cor
return(S)
}
portfolio_var = function(estimates){
d = estimates$d[1]
delta = estimates$delta[1]
epsilon = estimates$epsilon[1]
consecutive = estimates$consecutive[1]
ndim = 1000
nobs = 1250
phi = c(.1, .8)
# Starting workers
cores = detectCores() # detecting number of cores in the PC
cl = makeCluster(cores-2)
clusterEvalQ(cl, library("robcdcc"))
clusterEvalQ(cl, library("truncnorm"))
clusterEvalQ(cl, library("nlshrink"))
clusterEvalQ(cl, library("cellWise"))
clusterExport(cl, c("my_nlshrink", "%>%", "wrapper_cov"))
# Simulation
for(i in 10:10){
tryCatch({
cat('\n', 'pt ', i, '\n')
print(Sys.time())
data_path = paste(
'simulation_results/01__high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
sim = readRDS(data_path)
data = map(sim, 1)
seeds = map(sim, 2)
burnin_path = paste(
'simulation_results/00__burnin_high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
burnin_data = readRDS(burnin_path)
bdata = map(burnin_data, 1)
bseeds = map(burnin_data, 2)
all_data = lapply(1:10, function(x){
rbind(bdata[[x]], data[[x]])
})
# Validating
validate_burnin = all_data %>% lapply(anyDuplicated) %>% unlist
if(all(validate_burnin == 102) == FALSE){
print('burnin sample incompatible!')
break
}
# contaminating data
cont_seed = as.list(((i * 10 + 1) : (i * 10  + 10)))
cont_data = mapply(contaminate_high1, data, cont_seed,
MoreArgs = list(d=d, epsilon=epsilon,
consecutive=consecutive),
SIMPLIFY = FALSE)
# Getting estimates
estimates_i = estimates[estimates$seed == i, ]
q_estimates = estimates_i[estimates_i$model == 'Q', ]
# r_estimates = estimates_i[estimates_i$model == 'R', ]
seed = q_estimates$seed
q_phi = q_estimates[, c('X1', 'X2')] %>%
split(., seq(nrow(.))) %>% lapply(as.numeric)
# r_phi = r_estimates[, c('X1', 'X2')] %>%
#   split(., seq(nrow(.)))  %>% lapply(as.numeric)
# Portfolio variance
# Robust config
# robust_control = c(1.0465, 1.00045, .975)
# cy1 = robust_control[1]
# cy2 = robust_control[2]
# delta = robust_control[3]
# quantile for chi square distribution
# chisq1 = qchisq(delta, 1)
# chisq2 = qchisq(delta, ndim)
# Calculating all Qs * epsilon
q_Qs = mapply(calc_Qs, q_phi, cont_data, SIMPLIFY = FALSE)
# r_Qs = mapply(robust_calc_Qs, r_phi, cont_data,
#               MoreArgs = list(cy1 = cy1, chisq1 = chisq1),
#               SIMPLIFY = FALSE)
# Getting real S
S = lapply(seeds, function(x){
set.seed(x * 10)
rho = rtruncnorm(
ndim,
a = .5 - 4 * .1,
b = .5 + 4 * .1,
mean = .5,
sd = .1
)
S = rho %o% rho
diag(S) = rep(1, ndim)
return(S)
})
# Non-Linear Shrinkage covariance estimate
print(Sys.time())
cat('\n', 'shrinkage!', '\n')
wrapper_q_S = parLapply(cl=cl, q_Qs, wrapper_cov)
# wrapper_r_S = parLapply(cl=cl, r_Qs, wrapper_cov)
q_S = parLapply(cl=cl, wrapper_q_S, my_nlshrink)
# r_S = parLapply(cl=cl, wrapper_r_S, my_nlshrink)
cat('\n', 'S determinant!', '\n')
q_S_determinant =  q_S %>% lapply(determinant) %>%
map(1) %>% lapply(function(x){return(x[1])}) %>%
unlist
# r_S_determinant =  r_S %>% lapply(determinant) %>%
#   map(1) %>% lapply(function(x){return(x[1])}) %>%
#   unlist
# Portfolio variance
print(Sys.time())
cat('\n', 'portfolio_var!', '\n')
# variance_portfolio = parLapply(
#   cl = cl,
#   1:10,
#   fun=function(x){
#     tryCatch(
#       geral_calc_portfolio_variance(phi=phi,
#                                     q_phi=q_phi[[x]],
#                                     r_phi=r_phi[[x]],
#                                     rt=data[[x]], burn_rt=bdata[[x]],
#                                     cont_rt=cont_data[[x]],
#                                     S=S[[x]],
#                                     q_S=q_S[[x]], r_S=r_S[[x]],
#                                     cy2=cy2, chisq2=chisq2)
#     )}
# )
variance_portfolio = parLapply(
cl = cl,
1:10,
fun=function(x){
tryCatch(
qmvn_calc_portfolio_variance(
phi = phi,
q_phi = q_phi[[x]],
rt = data[[x]],
burn_rt = bdata[[x]],
cont_rt = cont_data[[x]],
S = S[[x]],
q_S = q_S[[x]]
)
)}
)
results = lapply(variance_portfolio, t) %>%
rlist::list.rbind(.) %>% as.data.frame
results$q_S_determinant = q_S_determinant
results$r_S_determinant = r_S_determinant
results$d = d
results$consecutive = consecutive
results$epsilon = epsilon
results$seed = i
results$delta = delta
# biding results
results_path = paste(
'simulation_results/03__high_dimension_var_n1250/qmvn_portfolio_var/pt_', i, '_epsilon_',
epsilon, '_d_', d, '_consecutive_', consecutive,'.Rds', sep = "")
# checkpoint
saveRDS(results, file = results_path)
}, error = function(e){cat("ERROR :",
conditionMessage(e), '. iteration:', i, "\n")})
}
stopCluster(cl)
}
estimates_groupby = estimates_df %>%
group_by(d, consecutive, epsilon) %>% group_split
'Estimate portfÃ³lio variance.'
# Packages
library(dplyr)
library(ggplot2)
library(rlist)
library(Metrics) # RMSE
library(purrr)
library(readr)
library(tidyr) # pivot_wider
library(data.table)
library(lemon) # shared subtitle for grid.arrange
library(miceadds) # source.all
library(Rcpp)
library(RcppArmadillo)
library(parallel)
library(robcdcc)
library(nlshrink)
library(readr)
estimates_groupby = estimates_df %>%
group_by(d, consecutive, epsilon) %>% group_split
estimates_groupby
portfolio_var(estimates_groupby[[1]])
portfolio_var = function(estimates){
d = estimates$d[1]
delta = estimates$delta[1]
epsilon = estimates$epsilon[1]
consecutive = estimates$consecutive[1]
ndim = 1000
nobs = 1250
phi = c(.1, .8)
# Starting workers
cores = detectCores() # detecting number of cores in the PC
cl = makeCluster(cores-2)
clusterEvalQ(cl, library("robcdcc"))
clusterEvalQ(cl, library("truncnorm"))
clusterEvalQ(cl, library("nlshrink"))
clusterEvalQ(cl, library("cellWise"))
clusterExport(cl, c("my_nlshrink", "%>%", "wrapper_cov"))
# Simulation
for(i in 10:10){
tryCatch({
cat('\n', 'pt ', i, '\n')
print(Sys.time())
data_path = paste(
'simulation_results/02__high_dimension/01__high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
sim = readRDS(data_path)
data = map(sim, 1)
seeds = map(sim, 2)
burnin_path = paste(
'simulation_results/02__high_dimension/00__burnin_high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
burnin_data = readRDS(burnin_path)
bdata = map(burnin_data, 1)
bseeds = map(burnin_data, 2)
all_data = lapply(1:10, function(x){
rbind(bdata[[x]], data[[x]])
})
# Validating
validate_burnin = all_data %>% lapply(anyDuplicated) %>% unlist
if(all(validate_burnin == 102) == FALSE){
print('burnin sample incompatible!')
break
}
# contaminating data
cont_seed = as.list(((i * 10 + 1) : (i * 10  + 10)))
cont_data = mapply(contaminate_high1, data, cont_seed,
MoreArgs = list(d=d, epsilon=epsilon,
consecutive=consecutive),
SIMPLIFY = FALSE)
# Getting estimates
estimates_i = estimates[estimates$seed == i, ]
q_estimates = estimates_i[estimates_i$model == 'Q', ]
# r_estimates = estimates_i[estimates_i$model == 'R', ]
seed = q_estimates$seed
q_phi = q_estimates[, c('X1', 'X2')] %>%
split(., seq(nrow(.))) %>% lapply(as.numeric)
# r_phi = r_estimates[, c('X1', 'X2')] %>%
#   split(., seq(nrow(.)))  %>% lapply(as.numeric)
# Portfolio variance
# Robust config
# robust_control = c(1.0465, 1.00045, .975)
# cy1 = robust_control[1]
# cy2 = robust_control[2]
# delta = robust_control[3]
# quantile for chi square distribution
# chisq1 = qchisq(delta, 1)
# chisq2 = qchisq(delta, ndim)
# Calculating all Qs * epsilon
q_Qs = mapply(calc_Qs, q_phi, cont_data, SIMPLIFY = FALSE)
# r_Qs = mapply(robust_calc_Qs, r_phi, cont_data,
#               MoreArgs = list(cy1 = cy1, chisq1 = chisq1),
#               SIMPLIFY = FALSE)
# Getting real S
S = lapply(seeds, function(x){
set.seed(x * 10)
rho = rtruncnorm(
ndim,
a = .5 - 4 * .1,
b = .5 + 4 * .1,
mean = .5,
sd = .1
)
S = rho %o% rho
diag(S) = rep(1, ndim)
return(S)
})
# Non-Linear Shrinkage covariance estimate
print(Sys.time())
cat('\n', 'shrinkage!', '\n')
wrapper_q_S = parLapply(cl=cl, q_Qs, wrapper_cov)
# wrapper_r_S = parLapply(cl=cl, r_Qs, wrapper_cov)
q_S = parLapply(cl=cl, wrapper_q_S, my_nlshrink)
# r_S = parLapply(cl=cl, wrapper_r_S, my_nlshrink)
cat('\n', 'S determinant!', '\n')
q_S_determinant =  q_S %>% lapply(determinant) %>%
map(1) %>% lapply(function(x){return(x[1])}) %>%
unlist
# r_S_determinant =  r_S %>% lapply(determinant) %>%
#   map(1) %>% lapply(function(x){return(x[1])}) %>%
#   unlist
# Portfolio variance
print(Sys.time())
cat('\n', 'portfolio_var!', '\n')
# variance_portfolio = parLapply(
#   cl = cl,
#   1:10,
#   fun=function(x){
#     tryCatch(
#       geral_calc_portfolio_variance(phi=phi,
#                                     q_phi=q_phi[[x]],
#                                     r_phi=r_phi[[x]],
#                                     rt=data[[x]], burn_rt=bdata[[x]],
#                                     cont_rt=cont_data[[x]],
#                                     S=S[[x]],
#                                     q_S=q_S[[x]], r_S=r_S[[x]],
#                                     cy2=cy2, chisq2=chisq2)
#     )}
# )
variance_portfolio = parLapply(
cl = cl,
1:10,
fun=function(x){
tryCatch(
qmvn_calc_portfolio_variance(
phi = phi,
q_phi = q_phi[[x]],
rt = data[[x]],
burn_rt = bdata[[x]],
cont_rt = cont_data[[x]],
S = S[[x]],
q_S = q_S[[x]]
)
)}
)
results = lapply(variance_portfolio, t) %>%
rlist::list.rbind(.) %>% as.data.frame
results$q_S_determinant = q_S_determinant
results$r_S_determinant = r_S_determinant
results$d = d
results$consecutive = consecutive
results$epsilon = epsilon
results$seed = i
results$delta = delta
# biding results
results_path = paste(
'simulation_results/03__high_dimension_var_n1250/qmvn_portfolio_var/pt_', i, '_epsilon_',
epsilon, '_d_', d, '_consecutive_', consecutive,'.Rds', sep = "")
# checkpoint
saveRDS(results, file = results_path)
}, error = function(e){cat("ERROR :",
conditionMessage(e), '. iteration:', i, "\n")})
}
stopCluster(cl)
}
portfolio_var(estimates_groupby[[1]])
library(rtruncnorm)
portfolio_var = function(estimates){
d = estimates$d[1]
delta = estimates$delta[1]
epsilon = estimates$epsilon[1]
consecutive = estimates$consecutive[1]
ndim = 1000
nobs = 1250
phi = c(.1, .8)
# Starting workers
cores = detectCores() # detecting number of cores in the PC
cl = makeCluster(cores-2)
clusterEvalQ(cl, library("robcdcc"))
clusterEvalQ(cl, library("truncnorm"))
clusterEvalQ(cl, library("nlshrink"))
clusterEvalQ(cl, library("cellWise"))
clusterExport(cl, c("my_nlshrink", "%>%", "wrapper_cov"))
# Simulation
for(i in 10:10){
tryCatch({
cat('\n', 'pt ', i, '\n')
print(Sys.time())
data_path = paste(
'simulation_results/02__high_dimension/01__high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
sim = readRDS(data_path)
data = map(sim, 1)
seeds = map(sim, 2)
burnin_path = paste(
'simulation_results/02__high_dimension/00__burnin_high_dimension_simulation_n1250/pt_', i, '.Rds',
sep = "")
burnin_data = readRDS(burnin_path)
bdata = map(burnin_data, 1)
bseeds = map(burnin_data, 2)
all_data = lapply(1:10, function(x){
rbind(bdata[[x]], data[[x]])
})
# Validating
validate_burnin = all_data %>% lapply(anyDuplicated) %>% unlist
if(all(validate_burnin == 102) == FALSE){
print('burnin sample incompatible!')
break
}
# contaminating data
cont_seed = as.list(((i * 10 + 1) : (i * 10  + 10)))
cont_data = mapply(contaminate_high1, data, cont_seed,
MoreArgs = list(d=d, epsilon=epsilon,
consecutive=consecutive),
SIMPLIFY = FALSE)
# Getting estimates
estimates_i = estimates[estimates$seed == i, ]
q_estimates = estimates_i[estimates_i$model == 'Q', ]
# r_estimates = estimates_i[estimates_i$model == 'R', ]
seed = q_estimates$seed
q_phi = q_estimates[, c('X1', 'X2')] %>%
split(., seq(nrow(.))) %>% lapply(as.numeric)
# r_phi = r_estimates[, c('X1', 'X2')] %>%
#   split(., seq(nrow(.)))  %>% lapply(as.numeric)
# Portfolio variance
# Robust config
# robust_control = c(1.0465, 1.00045, .975)
# cy1 = robust_control[1]
# cy2 = robust_control[2]
# delta = robust_control[3]
# quantile for chi square distribution
# chisq1 = qchisq(delta, 1)
# chisq2 = qchisq(delta, ndim)
# Calculating all Qs * epsilon
q_Qs = mapply(calc_Qs, q_phi, cont_data, SIMPLIFY = FALSE)
# r_Qs = mapply(robust_calc_Qs, r_phi, cont_data,
#               MoreArgs = list(cy1 = cy1, chisq1 = chisq1),
#               SIMPLIFY = FALSE)
# Getting real S
S = lapply(seeds, function(x){
set.seed(x * 10)
rho = truncnorm::rtruncnorm(
ndim,
a = .5 - 4 * .1,
b = .5 + 4 * .1,
mean = .5,
sd = .1
)
S = rho %o% rho
diag(S) = rep(1, ndim)
return(S)
})
# Non-Linear Shrinkage covariance estimate
print(Sys.time())
cat('\n', 'shrinkage!', '\n')
wrapper_q_S = parLapply(cl=cl, q_Qs, wrapper_cov)
# wrapper_r_S = parLapply(cl=cl, r_Qs, wrapper_cov)
q_S = parLapply(cl=cl, wrapper_q_S, my_nlshrink)
# r_S = parLapply(cl=cl, wrapper_r_S, my_nlshrink)
cat('\n', 'S determinant!', '\n')
q_S_determinant =  q_S %>% lapply(determinant) %>%
map(1) %>% lapply(function(x){return(x[1])}) %>%
unlist
# r_S_determinant =  r_S %>% lapply(determinant) %>%
#   map(1) %>% lapply(function(x){return(x[1])}) %>%
#   unlist
# Portfolio variance
print(Sys.time())
cat('\n', 'portfolio_var!', '\n')
# variance_portfolio = parLapply(
#   cl = cl,
#   1:10,
#   fun=function(x){
#     tryCatch(
#       geral_calc_portfolio_variance(phi=phi,
#                                     q_phi=q_phi[[x]],
#                                     r_phi=r_phi[[x]],
#                                     rt=data[[x]], burn_rt=bdata[[x]],
#                                     cont_rt=cont_data[[x]],
#                                     S=S[[x]],
#                                     q_S=q_S[[x]], r_S=r_S[[x]],
#                                     cy2=cy2, chisq2=chisq2)
#     )}
# )
variance_portfolio = parLapply(
cl = cl,
1:10,
fun=function(x){
tryCatch(
qmvn_calc_portfolio_variance(
phi = phi,
q_phi = q_phi[[x]],
rt = data[[x]],
burn_rt = bdata[[x]],
cont_rt = cont_data[[x]],
S = S[[x]],
q_S = q_S[[x]]
)
)}
)
results = lapply(variance_portfolio, t) %>%
rlist::list.rbind(.) %>% as.data.frame
results$q_S_determinant = q_S_determinant
results$r_S_determinant = r_S_determinant
results$d = d
results$consecutive = consecutive
results$epsilon = epsilon
results$seed = i
results$delta = delta
# biding results
results_path = paste(
'simulation_results/03__high_dimension_var_n1250/qmvn_portfolio_var/pt_', i, '_epsilon_',
epsilon, '_d_', d, '_consecutive_', consecutive,'.Rds', sep = "")
# checkpoint
saveRDS(results, file = results_path)
}, error = function(e){cat("ERROR :",
conditionMessage(e), '. iteration:', i, "\n")})
}
stopCluster(cl)
}
portfolio_var(estimates_groupby[[1]])
library(robcdcc)
library(robcdcc)
pt_4_epsilon_0.25_d_5_consecutive_FALSE <- readRDS("~/Documentos/Masters-degree/simulation_results/02__high_dimension/03__high_dimension_var_n1250/qmvn_portfolio_var/pt_4_epsilon_0.25_d_5_consecutive_FALSE.Rds")
pt_4_epsilon_0.25_d_5_consecutive_FALSE
